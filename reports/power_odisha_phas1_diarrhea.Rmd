---
title: "Power Considerations for Village RCT Odisha - Phase 1 - Diarrhea outcome"
author: Alex Lehner
date: July2023 #"2023-07-14"
output:
  pdf_document:
    highlight: tango
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = FALSE, include = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)

DIL_colors <- c(
  `red`        = "#8B0021",
  `yellow`     = "#FAA61A",
  `orange`     = "#E2821B",
  `black`      = "#303540",
  `light grey` = "#939698",
  `dark grey`  = "#8c8c8c")

DIL_cols <- function(...) {
  cols <- c(...)

  if (is.null(cols))
    return (DIL_colors)

  DIL_colors[cols]
}

DIL_palettes <- list(
  `main`  = DIL_cols("red", "light grey", "yellow", "black", "orange")
  #`main`  = DIL_cols("red", "yellow", "orange", "black", "light grey"),
)

DIL_pal <- function(palette = "main", reverse = FALSE, ...) {
  pal <- DIL_palettes[[palette]]

  if (reverse) pal <- rev(pal)

  colorRampPalette(pal, ...)
}


#' Color scale constructor for drsimonj colors
#'
#' @param palette Character name of palette in drsimonj_palettes
#' @param discrete Boolean indicating whether color aesthetic is discrete or not
#' @param reverse Boolean indicating whether the palette should be reversed
#' @param ... Additional arguments passed to discrete_scale() or
#'            scale_color_gradientn(), used respectively when discrete is TRUE or FALSE
#'
scale_color_DIL <- function(palette = "main", discrete = TRUE, reverse = FALSE, ...) {
  pal <- DIL_pal(palette = palette, reverse = reverse)

  if (discrete) {
    discrete_scale("colour", paste0("DIL_", palette), palette = pal, ...)
  } else {
    scale_color_gradientn(colours = pal(256), ...)
  }
}

#' Fill scale constructor for drsimonj colors
#'
#' @param palette Character name of palette in drsimonj_palettes
#' @param discrete Boolean indicating whether color aesthetic is discrete or not
#' @param reverse Boolean indicating whether the palette should be reversed
#' @param ... Additional arguments passed to discrete_scale() or
#'            scale_fill_gradientn(), used respectively when discrete is TRUE or FALSE
#'
scale_fill_DIL <- function(palette = "main", discrete = TRUE, reverse = FALSE, ...) {
  pal <- DIL_pal(palette = palette, reverse = reverse)

  if (discrete) {
    discrete_scale("fill", paste0("DIL_", palette), palette = pal, ...)
  } else {
    scale_fill_gradientn(colours = pal(256), ...)
  }
}
```



```{r, eval = TRUE}
#' Logit
#' @param x numeric
#' @return
#' @export
logit <- function(x) log(x/(1-x))

#' Inverse logit
#' @param x numeric
#' @return
#' @export
inv_logit <- function(x) {exp(x)/(1+exp(x))}
# THIS IS JUST plogis()


# takes in vector, calculates mean, rescales by the difference in means (only works for + at this stage because that's the direction the plogis transformation pushes the normal with mean 0)
rescale_pr <- function(x, pr) {
  if(length(pr) > 1) stop("probability to rescale on has to be of length 1")
  rescale_diff <- mean(x) - pr
  #if (rescale_diff < 0) stop("rescale difference has to be greater than 0")
  if (rescale_diff < 0) rescale_diff <- 0 # nothing happens if the rescale is negative bc it was inflated
  new_x <- x - rescale_diff # return new vector of probabilities
  #if (min(new_x) < 0) stop("probabilities cannot be negative")
  # just don't return them in case some probabilities are negative - not the cleanest fix but will not matter on agg
  #if (min(new_x) < 0) {return(x)} else {return(new_x)}
  # yet another iteration: make the VERY few negative probabilities to 0!
  new_x[new_x < 0] <- 0
  return(new_x)
}

```

This document lays out power calculations for a binary outcome, measured at the individual level, for a cluster randomized trial (C-RCT) in Odisha, India. The outcome of interest is diarrhea (approximate incidence rate of 5%) and the treatment (inline chlorination devices for clean water) is assigned at the household level for a complete cluster (a village).

The crucial assumptions for these calculations are:

- Intra-cluster correlation (ICC) [`0.01` and `0.02`]
- (Average) size of villages (U5 children) [`30` and `50`]
- Effect sice [`15%` and `20%`]

Autocorrelation of diarrhea incidence within individuals over time is considered here as well (in the form of an AR(1) process, roughly matching the values from Pickering et. al. (2019)), but it is less of a concern for power.

One of the main goals of the document is to illustrate the **trade-off between including more villages and increasing the number of survey rounds** to achieve power. 

The OLS specification that is assumed regresses a dummy variable of diarrhea incidence on a treatment dummy at the village level and one fixed effect for every round - exploiting only within-round variation and thus controlling for unobserved variables that vary over time:

$$Y_{ic} = \beta_1 \ T_c + \sum_{r=1}^3 \gamma_r \ ROUND_{ric} + \varepsilon_{ic},$$
with standard errors clustered at the village level (or the village by individual level to account for autocorrelation if the number of rounds, $r$, is greater than 1).

#### A quick comment on clustersizes.
Please note that none of the following calculations assume variation in clustersize. In reality these are going to vary and thus harm statistical power. For details and some descriptices (i.e. the CV of sizes per district), please have a look [at the dashboard that contains information on all census villages of Odisha](https://lehner.shinyapps.io/odisha_interactive/).
In practice, for the final randomization it could make sense to exclude very small and very big villages from the sample ex-ante in order to increase power. 

To inform our calculations, we first analyze data from a clustered chlorination intervention in Bangladesh from Pickering et al (2019, [The Lancet](https://www.thelancet.com/journals/langlo/article/PIIS2214-109X(19)30315-8/fulltext#gr1)).

The document is structured as follows:

1) Relevant descriptive statistics from Pickering et. al. (2019, The Lancet)
2) Simple benchmark calculations for only one survey round (plug-in formulas)
3) Consideration of multiple rounds of data collection (simulations, DGP targeted to match data in Pickering et. al. (2019))




```{r}

# There is also a dataset for a project that Akanksha worked on [linked here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VAFYV1&widget=dataverse@harvard).

```


# 1) Descriptives from Pickering et. al. (2019, The Lancet)

Pickering et. al. (2019): 100 shared water points (clusters) in two low-income urban communities in Bangladesh were randomly assigned (1:1) to have their drinking water automatically chlorinated at the point of collection by a solid tablet chlorine doser (intervention group) or to be treated by a visually identical doser that supplied vitamin C (active control group). The trial followed an open cohort design; all children younger than 5 years residing in households accessing enrolled water points were measured every 2–3 months during a 14-month follow-up period (children could migrate into or out of the cluster). The primary outcome was caregiver-reported child diarrhoea (more than 2 loose or watery stools in a 24-h period [WHO criteria]) with a 1-week recall, including all available childhood observations in the analyses. Children in the treatment group had less WHO-defined diarrhoea than did children in the control group (control 216 [10.0%] of 2154; treatment 156 [7.5%] of 2073; prevalence ratio 0.77, 95% CI 0.65–0.91).

They collected 7 rounds in total and found an effect of roughly 25% (diarrhea incidence reduction). The study was block-randomized by matching pairs, i.e. there are 50 randomization blocks with one cluster each assigned to treatment and control.


```{r, eval=TRUE, include=FALSE}
# find real world data from Amy's Bangladesh study in the Lancet
amy_lancet <- readstata13::read.dta13("../data/amypickering_lancet_BGD/chlorine_diarrhea_public.dta")
amy_lancet <- amy_lancet[!is.na(amy_lancet$uniqueid_entered), ]
# in paper we have 3142 and 3063 child-observations
(3142 + 3063) # number matches
table(amy_lancet$tr) # is the treatment variable

# POWER WORDING
# We	powered	the	study	to	detect	a	25%	reduction	in	the	WHO	case	definition	of	diarrhea;	our	sample	size	calculations	assumed,	based	on	prior	work,	that	diarrhea	prevalence	would	be	10%	among	children	<5	years	of	age	in	the	study	area.	We	conducted	the	power	calculations	using	a	cluster-level	means	approach	(comparing	the	mean	diarrhea	prevalence	by	cluster-time-point	between	groups)	because	we	did	not	have	a	good	estimate	for	the	intracluster	correlation	coefficient	for	diarrhea	by	water	point.	This	approach	treats	repeated	measures	at	one	point	in	time	the	same	as	repeated	measures	over	time.	Using	this	approach,	we	calculated	that	we	would	have	96%	power	with	the	study	design	(50	clusters	per	arm,	10	children	per	cluster)

table(amy_lancet$child_diarrhea)
amy_lancet$child_diarrhea1 <- ifelse(amy_lancet$child_diarrhea == "Yes", 1, 0) # make 01
table(amy_lancet$child_diarrhea1) # check
amy_lancet |> group_by(tr) |> summarise(meandia = mean(child_diarrhea1, na.rm = T))

# counts
amy_lancet |> count(round, tr, child_diarrhea1)

# ICC
fixest::feols(child_diarrhea1 ~ 0 | Block, data = amy_lancet)
fixest::feols(child_diarrhea1 ~ 0 | pumpid, data = amy_lancet) # 0.021 as compared to 0.025 in paper


logitamy <- glm(child_diarrhea1 ~ tr + round + Block, data = amy_lancet, family = "binomial")
summary(logitamy)


olsamy <- fixest::feols(child_diarrhea1 ~ tr | Block + round, data = amy_lancet)
summary(olsamy)
meanctrl <- mean(amy_lancet$child_diarrhea1[amy_lancet$tr != "trchlorine"]) 
(meanctrl + olsamy$coefficients) / meanctrl


# AUTOCORRELATION
# check how the lag works
data.frame(id = c(1,1,1,2,2,2), val = rep(1:3, 2)) |> group_by(id) |> 
  mutate(lagged = lag(val, n = 1, default = NA, order_by = id))

# sort by id and round first (is sorted by default? no but the order_By does the job):
amy_lancet <- amy_lancet %>%                           
  group_by(childidfull) %>%
  dplyr::mutate(laggedval = lag(child_diarrhea1, n = 1, default = NA, order_by = round))
#View(amy_lancet |> select(round, child_diarrhea1, laggedval, diarrhea_count))

amy_lancet |> group_by(round) |> summarise(corr = cor(child_diarrhea1, laggedval, use = "complete.obs"))

lm(child_diarrhea1 ~ laggedval + childidfull, data = amy_lancet) |> summary()




# wanna see ICC + block effect
# wanna do the calc with how many unique 1's in the diarrhea case
# run the regression with indiv FE and error
olsamy <- fixest::feols(child_diarrhea1 ~ tr | round + Block, data = amy_lancet)
summary(olsamy)
summary(olsamy, vcov = ~ Block)
summary(olsamy, vcov = ~ pumpid)
summary(olsamy, vcov = ~ childidfull)
summary(olsamy, vcov = ~ Block + childidfull)

# get the means per round
amy_lancet |> group_by(round) |> summarise(meandiarrhea = mean(child_diarrhea1))

# run regression per round and see if the weighted average fits:
roundreg <- amy_lancet |> group_by(round) |> summarise(ols = fixest::feols(child_diarrhea1 ~ tr | Block, data = cur_data())$coefficients,
                                           tstats = summary(fixest::feols(child_diarrhea1 ~ tr | Block, data = cur_data()))$coeftable[1,3],
                                           nobs = fixest::feols(child_diarrhea1 ~ tr | Block, data = cur_data())$nobs)

roundreg$ols |> weighted.mean(w = roundreg$nobs)

# check the round FE - i.e. the means in the control group in every round
test <- fixest::feols(child_diarrhea1 ~ tr | round, data = amy_lancet)
fixest::fixef(test) # |> plot()
```


```{r meansperround, eval = T, include = T }
knitr::kable(amy_lancet |> group_by(round,tr) |> summarise(meandiarrhea = mean(child_diarrhea1)) |> pivot_wider(id_cols = round, names_from = tr, values_from = meandiarrhea), caption = "Diarrhea incidence for every round of collection, broken down by treatment and control group.")

```



```{r}


# checking diarrhea frequency

amy_lancet <- amy_lancet |> group_by(childidfull) |> mutate(diarrhea_count = sum(child_diarrhea1))

table(amy_lancet$diarrhea_count)
table(amy_lancet$diarrhea_count[amy_lancet$tr == "chlorine"])
table(amy_lancet$diarrhea_count[amy_lancet$tr != "chlorine"])


# UNIQUE CHILDREN
amy_lancet$diarrhea_ever <- ifelse(amy_lancet$diarrhea_count > 0, 1, 0) # assign a 1 if a child ever had diarrhea at some point
amy_lancet_unique <- amy_lancet[!duplicated(amy_lancet$childidfull), ]
table(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr == "chlorine"])
table(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr != "chlorine"])
mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr == "chlorine"])
mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr != "chlorine"])
# effect on unique
mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr == "chlorine"]) / mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr != "chlorine"])

logitever <- glm(diarrhea_ever ~ tr, data = amy_lancet_unique, family = "binomial")
summary(logitever)
exp(logitever$coefficients[2])
# effsize
olsever<- fixest::feols(diarrhea_ever ~ tr, data = amy_lancet_unique)
summary(olsever)
meanctrl <- mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr != "chlorine"])
(meanctrl + olsever$coefficients[2]) / meanctrl

# effect is lower

# now we do a final thing and see how many new, independent cases get added with each round
amy_lancet$diarrhea_first <- 0

amy_lancet <- amy_lancet %>%
  #select(childidfull, round, child_diarrhea1, diarrhea_count) |> 
  group_by(childidfull) %>%
  arrange(round) |> # need to arrange by round here, otherwise the first assignment would not work - it rests on the thing being orderd
  mutate(first_1 = child_diarrhea1 == 1 & !duplicated(child_diarrhea1 == 1))  %>%
  arrange(childidfull)


amy_lancet$diarrhea_first <- ifelse(amy_lancet$first_1 == TRUE, 1, 0)


# get the percentage point add per round
roundsummary <- amy_lancet |> group_by(round) |> summarise(diarrheanew = mean(diarrhea_first)) 
roundsummary$diarrheanew |> sum()
amy_lancet |> group_by(round) |> summarise(diarrheanew = mean(diarrhea_first)) 

mean(amy_lancet$child_diarrhea1)
mean(amy_lancet$diarrhea_first)
mean(amy_lancet_unique$diarrhea_ever)
# THIS DOES NOT WORK BECAUSE NOT EVERY CHILD HAS SAME NUMBER OF ROUNDS

```


```{r autocorrest, eval = F, include = F}
# 100 villages with roughly 50
# broken down also by trt now
amy_lancet |> group_by(round, tr) |> summarise(diarrheanew = mean(diarrhea_first)) 
amy_lancet |> group_by(round) |> summarise(corr = cor(child_diarrhea1, laggedval, use = "complete.obs"))
amy_lancet |> group_by(round, tr) |> summarise(corr = cor(child_diarrhea1, laggedval, use = "complete.obs"))
```

#### Intra-cluster correlation (ICC)

```{r iccest, eval = T, include = F}
# ICC
fixest::feols(child_diarrhea1 ~ 0 | Block, data = amy_lancet)
fixest::feols(child_diarrhea1 ~ 0 | pumpid, data = amy_lancet) |> fixest::r2()# 0.021 as compared to 0.025 in paper
#ICC::ICCest(pumpid, child_diarrhea1, data = amy_lancet)$ICC
#ICCbin::iccbin(pumpid, child_diarrhea1, data = amy_lancet, method = "aov")

# period ICCs a bit more severe
amy_lancet |> group_by(round) |> summarise(ICC = ICC::ICCest(pumpid, child_diarrhea1, data = cur_data())$ICC)


# ICC for the block randomization
amy_lancet$residual4ICC <- lm(child_diarrhea1 ~ Block, data = amy_lancet)$resid

#ICC::ICCest(pumpid, residual4ICC, data = amy_lancet)$ICC


```

We calculate the raw ICC to be `r round(ICC::ICCest(pumpid, child_diarrhea1, data = amy_lancet)$ICC, 4)` and `r round(ICC::ICCest(pumpid, residual4ICC, data = amy_lancet)$ICC, 4)` after taking into account the blocking structure of the experiment. The sample size is not very large and we thus have reasons to believe that these estimates are not very precise. From earlier data work on child mortality with substantially larger sample sizes we obtained estimates of around 0.01. We therefore want to use 0.01 and 0.02 as benchmark values in our power calculations. 


### Checking counts per cluster


```{r, eval = T, include = T, fig.width = 4, fig.height = 3, fig.cap = "Diarrhea counts per cluster (pump), summed over all 7 rounds - approximately Poisson."}

amy_counts <- amy_lancet |> group_by(pumpid) |> summarise(n_people = n(),
                                                          diarrh_n = sum(child_diarrhea1),
                                                          tr = tr[1])

# diarrhea counts per pump
pois_lamb <- mean(amy_counts$diarrh_n)
pois_lamb1 <- sd(amy_counts$diarrh_n) # not too bad, looks like pois (obviously since it is counts)
library(ggh4x); library(fitdistrplus) # had troubles to fit the dpoits without these
#ggplot(data = amy_counts, aes(diarrh_n)) + geom_histogram(aes(y = stat(density))) + geom_density()
#ggplot(data = amy_counts, aes(diarrh_n)) + geom_histogram(aes(y = stat(density))) +  geom_density(aes(dpois(1:25, lambda = pois_lamb)))
#ggplot(data = amy_counts, aes(diarrh_n)) + geom_histogram(aes(y = stat(density))) + geom_density() + stat_theodensity(distri = "pois", col = "red")


ggplot(data = amy_counts) + geom_histogram(aes(diarrh_n)) + facet_grid(~ tr) + theme_bw()


#plot(dpois(1:25, lambda = pois_lamb))
```

\newpage

# 2) Benchmark calculations - one round only (plug-in formulas)

The following two plots show power as a function of the number of villages for two different average villages sizes: 30 and 50. The plots are grouped by ICC (`0.01` and `0.02`) and MDE (`10%` and `20%`). As noted in the introduction, the assumed diarrhea incidence is 5% across all specifications.

On the backend, the code uses the function `clusterPower::cpa.binary()` many times to compute each point in the plots.

The bottom line of these calculations is that for an MDE of 10% we are not going to be sufficiently powered. For the MDE of 20%, the following table summarizes the different scenarios where power is approximately 80% (extracted from the data that can be seen in the plots).

```{r}
# INSTRUCTIONS
# JULY 20th on Pickering slack:
# Hi Alex, I know your were coordinating with Akanksha to responding to MK, but I think we can play around with the power calcs and add that to the response. I discussed with him and it would like to see the tradeoffs between relying on frequent data collection vs X times the sample size. Would you be able to tell us which is the required NUMBER of villages for the following scenarios (an excel table with all combination would be helpful as a reference)
# 1 data collection at 24 months vs 3 data collections at 12-18-24
# ICC 0.02 and 0.01 (I agree on trying a couple)
# MDE 10% or 20% (MK wants less than 25%, lets give some scenarios to understand what is feasible)
# U5 children per village 30 or 50
# No block randomization (which I think it is the assumption now?)
# Even if you can do those quickly in stata and share the code that is helpful so we can modify things ourselves. Thansks a lot!


```


```{r, eval = T}
# first we define the function that we are going to iterate over
power_cpa.binary <- function(nclustotal, clusize_avg = nJ, ICC_choice = ICCval, 
                             pr_incidence = p_diar, MDE = MDEdia) {
  power.out <- clusterPower::cpa.binary(nsubjects = clusize_avg, 
                                        nclusters = nclustotal/2,
                                        CV = 0, # default is no variation in size, CV = 0
                                        ICC = ICC_choice, 
                                        p1 = pr_incidence, 
                                        p2 = pr_incidence * (1-MDE), 
                                          tol = .Machine$double.eps^.5)
  # return output in dataframe
  tibble(clusize_avg = clusize_avg, p_diar = pr_incidence, MDE = MDE, ICC = ICC_choice, 
         nclusters = nclustotal, power = power.out)
}
p_diar <- .05
#power_cpa.binary(10, clusize_avg = 50, ICC_choice = 0.01, pr_incidence = p_diar, MDE = .2)
clusternumbers <- seq(50, 900, by = 25) # define the 

# we want to do the checks across clusternumbers for different values of ICC and MDE - split by the two avg clustersizes
store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 50, ICC_choice = 0.01, pr_incidence = p_diar, MDE = .2)) |> bind_rows()

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 50, ICC_choice = 0.02, pr_incidence = p_diar, MDE = .2)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 50, ICC_choice = 0.01, pr_incidence = p_diar, MDE = .1)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 50, ICC_choice = 0.02, pr_incidence = p_diar, MDE = .1)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one


store$ICC <- as.factor(store$ICC)
store$MDE <- as.factor(store$MDE)

store50 <- store
```


```{r, eval = T}
# copy the exact same thing FOR VILLAGESIZE 30- ugly I know - quick fix
# we want to do the checks across clusternumbers for different values of ICC and MDE - split by the two avg clustersizes
rm(store)
store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 30, ICC_choice = 0.01, pr_incidence = p_diar, MDE = .2)) |> bind_rows()

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 30, ICC_choice = 0.02, pr_incidence = p_diar, MDE = .2)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 30, ICC_choice = 0.01, pr_incidence = p_diar, MDE = .1)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 30, ICC_choice = 0.02, pr_incidence = p_diar, MDE = .1)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one


store$ICC <- as.factor(store$ICC)
store$MDE <- as.factor(store$MDE)

store30 <- store

```


```{r, eval = T, include = T, }
# find the entry that is closest to 80 and 90%
closepowerfinder <- function(df, target_value) {df[which.min(abs(df$power - target_value)), ]}
store <- bind_rows(store30, store50)
storesubs <- store |> group_by(clusize_avg, MDE, ICC) |> do(closepowerfinder(.,.80))
storesubs <- storesubs |> filter(MDE == .2)
storesubs$power <- round(storesubs$power, 1)
names(storesubs) <- c("avg_clustersize", "diarrhea_pc", "MDE", "ICC", "villages_needed", "power")
knitr::kable(storesubs, caption = "Number of villages needed for different scenarios.")
```



```{r plotpoweravgsize30, eval = T, include = T,  fig.width=7, fig.height=4, fig.align='center'}


#ggplot(store, aes(x = nclusters, y = power, col = ICC, linetype = MDE, shape = MDE)) + 
p <- ggplot(store30, aes(x = nclusters, y = power, 
                       #col = interaction(ICC, MDE, sep = ' - '),
                       col = MDE,
                       #shape = interaction(MDE, ICC, sep = ' - '),
                       shape = ICC,
                       #linetype = interaction(MDE, ICC, sep = ' - '),
                       linetype = MDE,
                       )) + 
  geom_point() + geom_line() + 
  ggtitle("Power for total number of villages, avg size: 30") +
  theme_bw() +
  guides(colour = guide_legend(override.aes = list(shape = NA))) +
  labs(colour="MDE", shape="ICC") + scale_color_DIL() +
  scale_x_discrete(name = "Number of villages", limits = seq(50, 900, by = 50)) + 
  scale_y_discrete(name = "power", limits = seq(0, 1, by = .1), expand = c(0.05,0.1)) # shrink default expansion (0.6 for discrete) 

p

```




```{r plotpoweravgsize50, eval = T, include = T,  fig.width=7, fig.height=4, fig.align='center'}


#ggplot(store, aes(x = nclusters, y = power, col = ICC, linetype = MDE, shape = MDE)) + 
p <- ggplot(store50, aes(x = nclusters, y = power, 
                       #col = interaction(ICC, MDE, sep = ' - '),
                       col = MDE,
                       #shape = interaction(MDE, ICC, sep = ' - '),
                       shape = ICC,
                       #linetype = interaction(MDE, ICC, sep = ' - '),
                       linetype = MDE,
                       )) + 
  geom_point() + geom_line() + 
  ggtitle("Power for total number of villages, avg size: 50") +
  theme_bw() +
  guides(colour = guide_legend(override.aes = list(shape = NA))) +
  labs(colour="MDE", shape="ICC") + scale_color_DIL() +
  scale_x_discrete(name = "Number of villages", limits = seq(50, 900, by = 50)) + 
  scale_y_discrete(name = "power", limits = seq(0, 1, by = .1), expand = c(0.05,0.05)) # shrink default expansion (0.6 for discrete) 

p

```


\newpage

# 3) Simulation: multiple rounds of data collection

The simulation code that is used here models the data generating process (DGP) as draws from a Bernoulli distribution with a cluster level random effect that induces ICC. The events within individuals across rounds are modeled with a correlated error term that induces an AR(1) process to approximately match the data in Pickering et. al. (2019). The following simulations are carried out 1,000 times for each dot that is visualized.

To showcase that the code delivers meaningful power estimates, the following plots showcase the scenario where the number of rounds in the simulations is 1. It can be seen that the resulting power curves are very similar to the results from above, verifying that they can approximate the results from the plug-in formula. Note that the curve for MDEs of 10% is a bit wobbly due to the small effect size, a larger amount of iterations would straighten them out further. 


```{r plotsimpowerconfirm, eval = T, include = T,  fig.width=7, fig.height=8, fig.align='center', fig.cap='Showcase the working of the simulation code by matching the results from the plug-in formulas'}
# load the data that was stored from the power_odisha_diarrhea_runs.R file for one round
df.sim.1 <- readRDS("powerruns_stored/sim_1round_allvalues_2comparewithformulaoutput.RDS")


p <- ggplot(df.sim.1, aes(x = nclusters, y = power, 
                       #col = interaction(ICC, MDE, sep = ' - '),
                       col = MDE,
                       #shape = interaction(MDE, ICC, sep = ' - '),
                       shape = ICC,
                       #linetype = interaction(MDE, ICC, sep = ' - '),
                       linetype = MDE,
                       )) + 
  geom_point() + geom_line() + 
  #ggtitle("Power for total number of villages, avg size: 30") +
  theme_bw() +
  guides(colour = guide_legend(override.aes = list(shape = NA))) +
  labs(colour="MDE", shape="ICC") + scale_color_DIL() +
  scale_x_discrete(name = "Number of villages", limits = seq(50, 900, by = 50)) + 
  scale_y_discrete(name = "power", limits = seq(0, 1, by = .1), expand = c(0.025,0.05)) +
  facet_wrap( ~ clusize, nrow = 2)# shrink default expansion (0.6 for discrete) 

p

```




```{r}


set.seed(123)  # Set seed for reproducibility
nV <- 100 # number of villages
nJ <- 50 # cluster size - COULD bake in variation in cluster size to match a CV
p_diar <- .05
vil <- rep(1:nV, each = nJ) # creating cluster variable
vil_frame <- data.frame(childid = 1:(nV*nJ), vilid = as.factor(vil))
MDEdia <- .25
nrounds <- 3 # how many rounds to you want to collect
ICCval <- .0135
indiv_sd <- .5 # the standard deviation is mean inflating (pushes up the baseline PR, has to do with the inverse logit) - that's why I decided to rescale
# SD of .5 gives same power as formula for both ICC = 0 and ICC = 0.02
indiv_ar <- .5

clus_sd <- 0.4 # with 1 round: .5 was the value that i initially had to get roughly .014, .7 gave .03 but with inflated base rate | .6 gave 0.022 - slightly inflate base rate | .55 gave 0.018 | .575 gave .0208
# .4 gave ICC of 0.01  
# SCENARIO ICC 0: clussd: 0 indivsd: .5 ... POWER 59, indivsd: 1, POWER 58
# SCENARIO ICC 0.02 clussd: .575 indivsd: .5
# SCENARIO ICC 0.01 clussd: .4 individsd: .5 ... POWER 40 (instead of 32 acc to formula)

# LOG: without AR1, we had an indiv sd of 0.005 and a 0,.5 draw for cluster - this gave ICC of 0.015 on avg

# do a regular powercalc and try to get this right in a benchmark simulation with only one round
# a simulation with one round should give roughly a power to this number, otherwise something is off
# ... attention PER CONDITION, so divide by 2
clusterPower::cpa.binary(nsubjects = nJ, 
                         nclusters = nV/2,
                                        CV = 1,
                                        ICC = 0.01, 
                                        p1 = p_diar, 
                                        p2 = p_diar * (1-MDEdia), 
                                          tol = .Machine$double.eps^.5)
# without ICC, nested in the above for ICC = 0
power.prop.test(p1 = p_diar, p2 = p_diar * (1-MDEdia), n = nJ*(nV/2))
# with one round in the simulation, you should get roughly this power number
# if power is too high in the simulations, probably your error is not dispersed enough
# test <- ICCbin::rcbin(prop = p_diar, prvar = 0, noc = nV, csize = nJ, csvar = 0, rho = .01)
# mean(test$y)
# ICC::ICCest(cid, y, data = test)$ICC
# ICCbin dominates fabricatr?

nsim <- 500
runframe <- data.frame(runid = 1:nsim, 
                       pointest = NA, tstat = NA, 
                       pointest1 = NA, tstat1 = NA, 
                       cor12 = NA, cor23 = NA,
                       meantr = NA, meanctrl = NA,
                       ICC = NA) # container to hold the simulation runs

# started off with a loop in the initial iterative process
# ... idea is to bring it into a function that then can be vectorized to improve the speed (later, IF NEEDED ONLY)

# make sure to check the resulting means in T and C after you changed the ar, sd parameters etc - they push up the baseline rate too high if the values are too high
# if you adjust ICC, you most probably also have to adjust the AR1 process - and vice versa
for (i in 1:nrow(runframe)) {
  # assign treated
  vil_frame_sim <- vil_frame # copy over because we grow the frame in every iteration
  treated <- sample(1:nV, nV/2)
  vil_frame_sim$tr <- ifelse(vil_frame_sim$vilid %in% treated, 1, 0)
  # Original binary vector, split for treated / untreated
  vil_frame_sim$round <- NA
  # replicate frame to match number of rounds
  vil_frame_sim <- bind_rows(replicate(nrounds, vil_frame_sim, simplify = FALSE))
  vil_frame_sim$round <- rep(1:nrounds, each = nV*nJ)
  # MDE reduction
  p_diartr <- p_diar * (1 - MDEdia)
  vil_frame_sim$diarrhea <- NA
  
  # ----------------------------------------------------------------------------
  # INDIVIDUAL LEVEL probabilities
  # 1st way would be to model the full dataframe rightaway rep(frame, n-period), this would allow model the AR1 process directly in one go ... c(sapply(1:n_obs, function(x) {arima.sim(list(order=c(1,0,0), ar=gamma), n=n_periods
  # 2nd way chosen here: 
  # ... expand data period by period (this allowed to explore different ICC sampling strategies in the beginning)
  # ... 
  # n_ctr <- nV*nJ/2 # dump later
  # n_tr  <- nV*nJ/2 # dump later
  ## INDIVIDUAL LEVEL EFFECT
  if (nrounds == 1) { # if only one round, we just draw from normal one time
    #indiv_e <- data.frame(err = rnorm(nV*nJ, 0, indiv_sd), round = 1) # individual level error - has to be somewhat small
    vil_frame_sim$err <- rnorm(nV*nJ, 0, indiv_sd) # having the error in the vilframe makes it easier to subset by round below
  } else { # model the AR1 process, replicate the AR1 process over nrounds nobs (i.e. nV*nJ) times
    vil_frame_sim$err <- c(sapply(1:(nV*nJ), function(x) {arima.sim(list(order=c(1,0,0), ar=indiv_ar), n = nrounds, sd = indiv_sd)}))
  }
  ## CLUSTER LEVEL EFFECT (to model ICC)
  clust_e <- rnorm(nV, 0, clus_sd) # random effect (.5 gave an ICC of .015-.02)
  b1      <- 1 # keep it 1 if you dont want to scale up
  # add a random effect / cluster component + an error term (can switch off by setting the rnorm 0,0)
  # rewrote to have a logit here and the pr (from the plogis/inv_logit transformation) inside the rbinom
  # ... so that I can introduce an AR1 process easier
  logit_ctr   <- logit(p_diar) + b1*clust_e[vil_frame_sim$vilid[vil_frame_sim$tr == 0]]
  logit_ctr_1 <- logit_ctr + vil_frame_sim$err[vil_frame_sim$round == 1 & vil_frame_sim$tr == 0]
  resc_p_ctr_1 <- rescale_pr(inv_logit(logit_ctr_1), p_diar) # rescale s.t. the mean prob is the correct diar prob, see in the appendix why and how inv_logit inflates the mean of the cluster error
  # treatment probabilities
  logit_tr    <- logit(p_diartr) + b1*clust_e[vil_frame_sim$vilid[vil_frame_sim$tr == 1]]
  logit_tr_1  <- logit_tr + vil_frame_sim$err[vil_frame_sim$round == 1 & vil_frame_sim$tr == 1]
  resc_p_tr_1 <- rescale_pr(inv_logit(logit_tr_1), p_diartr) # rescale s.t. the mean prob is the correct diar prob, see in the appendix why and how inv_logit inflates the mean of the cluster error
  
  vil_frame_sim$diarrhea[vil_frame_sim$tr == 0 &
                           vil_frame_sim$round == 1] <- rbinom((nV*nJ)/2, 1, resc_p_ctr_1)# inv_logit(logit_ctr_1))
  vil_frame_sim$diarrhea[vil_frame_sim$tr == 1 &
                           vil_frame_sim$round == 1] <- rbinom((nV*nJ)/2, 1, resc_p_tr_1)# inv_logit(logit_tr_1))
  
  # ----------------------------------------------------------------------------
  # POPULATION LEVEL with ICCbinary
  # vil_frame_sim$diarrhea[vil_frame_sim$tr == 0 & 
  #                          vil_frame_sim$round == 1] <- fabricatr::draw_binary_icc(p_diar, clusters = vil_frame_sim$vilid[vil_frame_sim$tr == 0], ICC = ICCval)
  # vil_frame_sim$diarrhea[vil_frame_sim$tr == 1 & 
  #                          vil_frame_sim$round == 1] <- fabricatr::draw_binary_icc(p_diartr, clusters = vil_frame_sim$vilid[vil_frame_sim$tr == 1], ICC = ICCval)
  
  # ICCBIN APPROACH:
  # vil_frame_sim$diarrhea[vil_frame_sim$tr == 0 &
  #                          vil_frame_sim$round == 1] <- ICCbin::rcbin(prop = p_diar, prvar = 0, noc = nV, csize = nJ, csvar = 0, rho = ICCval)$y
  # vil_frame_sim$diarrhea[vil_frame_sim$tr == 1 &
  #                          vil_frame_sim$round == 1] <- ICCbin::rcbin(prop = p_diartr, prvar = 0, noc = nV, csize = nJ, csvar = 0, rho = ICCval)$y
  
  # ----------------------------------------------------------------------------
  # assign diarrhea cases - "population level", i.e. just 0,1 draws according to the probabilities
  # vil_frame_sim$diarrhea[vil_frame_sim$tr == 0 & 
  #                          vil_frame_sim$round == 1] <- sample(c(0, 1), prob = c(1-p_diar, p_diar), (nV*nJ)/2, replace = TRUE)
  # vil_frame_sim$diarrhea[vil_frame_sim$tr == 1 & 
  #                          vil_frame_sim$round == 1] <- sample(c(0, 1), prob = c(1-p_diartr, p_diartr), (nV*nJ)/2, replace = TRUE)
  if(nrounds > 1) { # this allows me to build on top of the round with an AR process
    for (t in 2:nrounds) {
      # ----------------------------------------------------------------------------
      # POPULATION PLAIN VANILLA
      # vil_frame_sim$diarrhea[vil_frame_sim$tr == 0 &
      #                      vil_frame_sim$round == t] <- sample(c(0, 1), prob = c(1-p_diar, p_diar), (nV*nJ)/2, replace = TRUE)
      # vil_frame_sim$diarrhea[vil_frame_sim$tr == 1 &
      #                          vil_frame_sim$round == t] <- sample(c(0, 1), prob = c(1-p_diartr, p_diartr), (nV*nJ)/2, replace = TRUE)
      # ----------------------------------------------------------------------------
      # POPULATION WITH ICC
      # vil_frame_sim$diarrhea[vil_frame_sim$tr == 0 & 
      #                      vil_frame_sim$round == t] <- fabricatr::draw_binary_icc(p_diar, clusters = vil_frame_sim$vilid[vil_frame_sim$tr == 0], ICC = ICCval)
      # vil_frame_sim$diarrhea[vil_frame_sim$tr == 1 & 
      #                      vil_frame_sim$round == t] <- fabricatr::draw_binary_icc(p_diartr, clusters = vil_frame_sim$vilid[vil_frame_sim$tr == 1], ICC = ICCval)
      # ----------------------------------------------------------------------------
      # INDIVIDUAL ADDONS (with AR1 now)
      logit_ctr_n <- logit_ctr + vil_frame_sim$err[vil_frame_sim$round == t & vil_frame_sim$tr == 0]
      logit_tr_n  <- logit_tr + vil_frame_sim$err[vil_frame_sim$round == t & vil_frame_sim$tr == 1]
            # same rescaling as above\
      resc_p_ctr_n <- rescale_pr(inv_logit(logit_ctr_n), p_diar)
      resc_p_tr_n <- rescale_pr(inv_logit(logit_tr_n), p_diartr)
      
      vil_frame_sim$diarrhea[vil_frame_sim$tr == 0 &
                           vil_frame_sim$round == t] <- rbinom((nV*nJ)/2, 1, resc_p_ctr_n) #inv_logit(logit_ctr_n))
      vil_frame_sim$diarrhea[vil_frame_sim$tr == 1 &
                           vil_frame_sim$round == t] <- rbinom((nV*nJ)/2, 1, resc_p_tr_n) #inv_logit(logit_tr_n))
    }
  }
  
  # run the regression, cluster at treatment assignment level to get SEs right
  # ... no block randomization (don't know how much variation we would explain with a block FE as of now anyways)
  regobj <- summary(fixest::feols(diarrhea ~ tr | round, data = vil_frame_sim), vcov = ~ vilid + childid)
  runframe$pointest[i] <- regobj$coeftable[1,1] # point estimate
  runframe$tstat[i]    <- regobj$coeftable[1,3] # tstat
  regobj <- summary(fixest::feols(diarrhea ~ tr | round, data = vil_frame_sim))
  runframe$pointest1[i] <- regobj$coeftable[1,1] # point estimate
  runframe$tstat1[i]    <- regobj$coeftable[1,3] # tstat
  #cat("done with run ", i)
  # some other info
  if (nrounds > 1) {
      runframe$cor12[i] <- cor(vil_frame_sim$diarrhea[vil_frame_sim$round == 1], vil_frame_sim$diarrhea[vil_frame_sim$round == 2])
      runframe$cor23[i] <- cor(vil_frame_sim$diarrhea[vil_frame_sim$round == 2], vil_frame_sim$diarrhea[vil_frame_sim$round == 3])
  }

  runframe$meantr[i]   <- vil_frame_sim$diarrhea[vil_frame_sim$tr == 1 & vil_frame_sim$round == 1] |> mean()
  runframe$meanctrl[i] <- vil_frame_sim$diarrhea[vil_frame_sim$tr == 0 & vil_frame_sim$round == 1] |> mean()
  
  # take care of the warning
  #runframe$ICC[i] <- ICC::ICCest(vilid, diarrhea, data = vil_frame_sim)$ICC
  runframe$ICC[i] <- fixest::r2(fixest::feols(diarrhea ~ 0 | vilid, data = vil_frame_sim), "ar2")

}

# if the mean is off of the p_diar then the rescaling did not go through bc there was one negative probability
mean(runframe$meanctrl)
mean(runframe$meantr)
mean(abs(runframe$tstat) > 1.96)
mean(abs(runframe$tstat1) > 1.96)
mean(runframe$ICC)
# AR Was between .03 and .15
mean(runframe$cor12)
mean(runframe$cor23)

ICC::ICCest(vilid, diarrhea, data = vil_frame_sim)$ICC
ICC::ICCest(vilid, diarrhea, data = vil_frame_sim[vil_frame_sim$tr == 0, ])$ICC

vil_frame_sim <- vil_frame_sim |> group_by(childid) |> mutate(diarrhea_count = sum(diarrhea))
table(vil_frame_sim$diarrhea_count)

```



```{r}
# analysis / checking
vil_frame_sim <- vil_frame_sim %>%                           
  group_by(childid) %>%
  dplyr::mutate(laggedval = lag(diarrhea, n = 1, default = NA, order_by = round))
vil_frame_sim |> group_by(round, tr) |> summarise(diarrhea = mean(diarrhea)) 
cor(vil_frame_sim$diarrhea[vil_frame_sim$round == 1], vil_frame_sim$diarrhea[vil_frame_sim$round == 2])
vil_frame_sim |> filter(round > 1) |> group_by(round) |> summarise(corr = cor(diarrhea, laggedval, use = "complete.obs"))


# checking how the correlation compounds over time (if there is some snowballing going on)
round1 <- sample(c(0, 1), prob = c(1-p_diar, p_diar), (nV*nJ), replace = TRUE)
round1 <- c(round1, round1tr)
# Compute the correlation
round2 <- add_round(round1)
cor(round1, round2)
mean(round1)
mean(round2[1:2500])
mean(round2[2500:5000])
round3 <- add_round(round2)
cor(round3, round2)
mean(round3)
round4 <- add_round(round3)
cor(round3, round4)
mean(round4)
mean(round4[1:2500])
mean(round4[2500:5000])


```



```{r}



```




```{r}
# then on July12th there was a response by MK

# Hi, 
# 
# Thanks so much for your email. Sone quick reactions
# 
# I think we need to pick up smaller than 25% reductions in diarrhea. 
# 
# I don't think we can afford three rounds of data collection within our current budget. Can we get cost estimates? These calculations suggest the ratio of cost of mortality to diarrhea power is high for ILC India relative to individually randomizable treatments.
# 
# what ICC is being used?
# 
# I think it's critical to take into account intra-cluster correlation. 
# 
#  Can you share all the parameters that are assumed? 
# 
# Does this involve any baseline data collection? 
# 
# IIt would be great if you could share the code that you're using as well. 
# 
# I'm a little confused because I thought there was supposed to be 150 villages rather than 100. 
# 
# Best Wishes,
# Michael

# ------------------------
 # Akankhsa then said in Person on July 13th at Booth during DIL teamweek that they only put 150 to have buffer (befoer it was 80 and they put 100 to have buffer). She also said that new village numbers will be based on outcome of power calculations


# ------------------------
# later the same day, Elisa wrote on the pickering slack
# Hi 
# @Alex Lehner
#  can you calculate how many villages we need if we want to do 1 data collection for U2 mortality with ICC NOT zero (we considered 0.01 in the past right?). What MK wants to know is the trade-off to do 1 data collection with 3 times the sample or 3 rounds of data collection with less sample. We are going to ask for additional funds to GiveWell so we would like to budget for both scenarios after we know the required sample size for a MDE < 25% (maybe 20%? or maybe 15%, but with 95% power, NO less). Then we can put together the budget and think about the trade-offs 0 Thanks a lot!



# -----------
# Not included in response to Elisa: Just as a quick back of the envelope to anticipate: for just having one round, given 50 U5children per village, a 95% powered MDE of 20% would require 550 villages




```


