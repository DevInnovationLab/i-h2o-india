---
title: "Power Considerations for Village RCT Odisha - Phase 1 - Diarrhea outcome"
author: Alex Lehner
date: July2023 (update with 7.5pc incidence - ONLY for Ch1 however, the simulations in Ch2 are the old ones with 5pc incidence) #"2023-07-14"
header-includes:
   - \usepackage{lineno}
   - \linenumbers
output:
  pdf_document:
    highlight: tango
urlcolor: blue
linestretch: 1.5
fontsize: 12pt
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = FALSE, include = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(DILmisc) # color stuff is now in there - no need to copy over the defining code anymroe

# DIL_colors <- c(
#   `red`        = "#8B0021",
#   `yellow`     = "#FAA61A",
#   `orange`     = "#E2821B",
#   `black`      = "#303540",
#   `light grey` = "#939698",
#   `dark grey`  = "#8c8c8c")
# 
# DIL_cols <- function(...) {
#   cols <- c(...)
# 
#   if (is.null(cols))
#     return (DIL_colors)
# 
#   DIL_colors[cols]
# }
# 
# DIL_palettes <- list(
#   `main`  = DIL_cols("red", "light grey", "yellow", "black", "orange")
#   #`main`  = DIL_cols("red", "yellow", "orange", "black", "light grey"),
# )
# 
# DIL_pal <- function(palette = "main", reverse = FALSE, ...) {
#   pal <- DIL_palettes[[palette]]
# 
#   if (reverse) pal <- rev(pal)
# 
#   colorRampPalette(pal, ...)
# }
# 
# 
# #' Color scale constructor for drsimonj colors
# #'
# #' @param palette Character name of palette in drsimonj_palettes
# #' @param discrete Boolean indicating whether color aesthetic is discrete or not
# #' @param reverse Boolean indicating whether the palette should be reversed
# #' @param ... Additional arguments passed to discrete_scale() or
# #'            scale_color_gradientn(), used respectively when discrete is TRUE or FALSE
# #'
# scale_color_DIL <- function(palette = "main", discrete = TRUE, reverse = FALSE, ...) {
#   pal <- DIL_pal(palette = palette, reverse = reverse)
# 
#   if (discrete) {
#     discrete_scale("colour", paste0("DIL_", palette), palette = pal, ...)
#   } else {
#     scale_color_gradientn(colours = pal(256), ...)
#   }
# }
# 
# #' Fill scale constructor for drsimonj colors
# #'
# #' @param palette Character name of palette in drsimonj_palettes
# #' @param discrete Boolean indicating whether color aesthetic is discrete or not
# #' @param reverse Boolean indicating whether the palette should be reversed
# #' @param ... Additional arguments passed to discrete_scale() or
# #'            scale_fill_gradientn(), used respectively when discrete is TRUE or FALSE
# #'
# scale_fill_DIL <- function(palette = "main", discrete = TRUE, reverse = FALSE, ...) {
#   pal <- DIL_pal(palette = palette, reverse = reverse)
# 
#   if (discrete) {
#     discrete_scale("fill", paste0("DIL_", palette), palette = pal, ...)
#   } else {
#     scale_fill_gradientn(colours = pal(256), ...)
#   }
# }
```



```{r, eval = TRUE}
#' Logit
#' @param x numeric
#' @return
#' @export
logit <- function(x) log(x/(1-x))

#' Inverse logit
#' @param x numeric
#' @return
#' @export
inv_logit <- function(x) {exp(x)/(1+exp(x))}
# THIS IS JUST plogis()


# takes in vector, calculates mean, rescales by the difference in means (only works for + at this stage because that's the direction the plogis transformation pushes the normal with mean 0)
rescale_pr <- function(x, pr) {
  if(length(pr) > 1) stop("probability to rescale on has to be of length 1")
  rescale_diff <- mean(x) - pr
  #if (rescale_diff < 0) stop("rescale difference has to be greater than 0")
  if (rescale_diff < 0) rescale_diff <- 0 # nothing happens if the rescale is negative bc it was inflated
  new_x <- x - rescale_diff # return new vector of probabilities
  #if (min(new_x) < 0) stop("probabilities cannot be negative")
  # just don't return them in case some probabilities are negative - not the cleanest fix but will not matter on agg
  #if (min(new_x) < 0) {return(x)} else {return(new_x)}
  # yet another iteration: make the VERY few negative probabilities to 0!
  new_x[new_x < 0] <- 0
  return(new_x)
}

```

This document lays out power calculations for a binary outcome, measured at the individual level, for a cluster randomized trial (C-RCT) in Odisha, India. The outcome of interest is diarrhea (approximate incidence rate of 5% [latest data from NFHS] - **ATTENTION: in this iteration, the incidence rate is increased to 7.5%**) and the treatment (inline chlorination devices for clean water) is assigned for a complete cluster (a village).

The crucial assumptions for these calculations are:

- Intra-cluster correlation (ICC) [`0.01` and `0.02`]
- (Average) size of villages (U5 children) [`30` and `50`]
- Effect size [`10%` and `20%`]

One of the main goals of the document is to illustrate the **trade-off between including more villages and increasing the number of survey rounds** to achieve power.
Autocorrelation of diarrhea incidence within individuals over time is considered here as well (in the form of an AR(1) process, roughly matching the values from Pickering et. al. (2019)). For computational reasons the current benchmark version of multi-round simulations does not consider this, however, because the autocorrelation of the binary outcome is not too strong (see analysis of Pickering data below) and thus not affecting power significantly.

#### Gains from extra rounds of data collection.
The bottom line is that there are substantial power gains from extra rounds. The intuition for this is that with every new round we get additional diarrhea cases. This is different from a scenario with a continuous outcome variable where power gains from extra periods stem mostly from averaging out noise in $Y$ (see the 2012 paper by McKenzie).

The OLS specification that is assumed is the one from Pickering et. al. (2019). It regresses an indicator variable of diarrhea incidence on a treatment indicator at the village level and one fixed effect for every round - exploiting only within-round variation and thus controlling for unobserved variables that change over time:

$$Y_{ic} = \beta_1 \ T_c + \sum_{r=1}^3 \gamma_r \ ROUND_{ric} + \varepsilon_{ic},$$
with standard errors clustered at the village level (or the village by individual level to account for autocorrelation if the number of rounds, $r$, is greater than 1).

#### A quick comment on cluster sizes.
Please note that none of the following calculations assume variation in cluster size. In reality these are going to vary and thus harm statistical power. For details and some descriptives (i.e. the CV of sizes per district), please have a look [at the dashboard that contains information on all census villages of Odisha](https://lehner.shinyapps.io/odisha_interactive/).
In practice, for the final randomization it could make sense to exclude very small and very big villages from the sample ex-ante in order to increase power (I am thinking of somewhere around the 5th and 95th percentile - depending on the state).

To inform our calculations, we analyze data from a clustered chlorination intervention in Bangladesh from Pickering et al (2019, [The Lancet](https://www.thelancet.com/journals/langlo/article/PIIS2214-109X(19)30315-8/fulltext#gr1)).

The document is structured as follows:

1) Simple benchmark calculations for only one survey round (**plug-in formulas**)
2) Consideration of multiple rounds of data collection (**simulations**, DGP targeted to match data in Pickering et. al. (2019))
3) Relevant descriptive statistics from Pickering et. al. (2019)




```{r}

# There is also a dataset for a project that Akanksha worked on [linked here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VAFYV1&widget=dataverse@harvard).

```



# 1) Benchmark calculations - one round only (plug-in formulas)

The following two plots show power as a function of the number of villages for two different average villages sizes: 30 and 50. The plots are grouped by ICC (`0.01` and `0.02`) and MDE (`10%` and `20%`). As noted in the introduction, the assumed diarrhea incidence is 5% across all specifications.

The plug-in formula that is being used is implemented in the R function `clusterPower::cpa.binary()`. The stata equivalent is `clustersampsi, binomial`.
An example on how to use the code:
```{r illustratepluginformula, include = TRUE, eval = FALSE, echo = TRUE}
cpa.binary(nsubjects = 50, # average clustersize
           CV = 0, # no variation in clustersize assumed
           power = .8, # desired power
           ICC = 0.01, 
           p1 = 0.05, # diarrhea incidence of 5%
           p2 = 0.05 * (1 - 0.20)) # MDE of 20%
# Function returns the number of clusters needed PER condition, i.e. multiply by two.
```



The plots below **trace out the full power curve** for many potential combinations of inputs.
The bottom line of these calculations is that for an MDE of 10% we are not going to be sufficiently powered. For the MDE of 20%, the following table summarizes the different scenarios where power is approximately 80% (extracted from the data that can be seen in the plots).

```{r}
# INSTRUCTIONS
# JULY 20th on Pickering slack:
# Hi Alex, I know your were coordinating with Akanksha to responding to MK, but I think we can play around with the power calcs and add that to the response. I discussed with him and it would like to see the tradeoffs between relying on frequent data collection vs X times the sample size. Would you be able to tell us which is the required NUMBER of villages for the following scenarios (an excel table with all combination would be helpful as a reference)
# 1 data collection at 24 months vs 3 data collections at 12-18-24
# ICC 0.02 and 0.01 (I agree on trying a couple)
# MDE 10% or 20% (MK wants less than 25%, lets give some scenarios to understand what is feasible)
# U5 children per village 30 or 50
# No block randomization (which I think it is the assumption now?)
# Even if you can do those quickly in stata and share the code that is helpful so we can modify things ourselves. Thansks a lot!


```


```{r, eval = T}
# first we define the function that we are going to iterate over
power_cpa.binary <- function(nclustotal, clusize_avg = nJ, ICC_choice = ICCval, 
                             pr_incidence = p_diar, MDE = MDEdia) {
  power.out <- clusterPower::cpa.binary(nsubjects = clusize_avg, 
                                        nclusters = nclustotal/2,
                                        CV = 0, # default is no variation in size, CV = 0
                                        ICC = ICC_choice, 
                                        p1 = pr_incidence, 
                                        p2 = pr_incidence * (1-MDE), 
                                          tol = .Machine$double.eps^.5)
  # return output in dataframe
  tibble(clusize_avg = clusize_avg, p_diar = pr_incidence, MDE = MDE, ICC = ICC_choice, 
         nclusters = nclustotal, power = power.out)
}
p_diar <- .05
# CHANGE IN THIS ITERATION
p_diar <- .075 
#power_cpa.binary(10, clusize_avg = 50, ICC_choice = 0.01, pr_incidence = p_diar, MDE = .2)
clusternumbers <- seq(50, 900, by = 25) # define the 

# NOTE: THIS IS AN AWFUL WAY TO WRITE THE CODE - TOO MUCH REPLICATION
# THIS IS AGAINST THE DIL ANALYTICS PRINCIPLES ... only done due to time constraints
# we want to do the checks across clusternumbers for different values of ICC and MDE - split by the two avg clustersizes
store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 50, ICC_choice = 0.01, pr_incidence = p_diar, MDE = .2)) |> bind_rows()

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 50, ICC_choice = 0.02, pr_incidence = p_diar, MDE = .2)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 50, ICC_choice = 0, pr_incidence = p_diar, MDE = .2)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 50, ICC_choice = 0.01, pr_incidence = p_diar, MDE = .1)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 50, ICC_choice = 0.02, pr_incidence = p_diar, MDE = .1)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 50, ICC_choice = 0, pr_incidence = p_diar, MDE = .1)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one


store$ICC <- as.factor(store$ICC)
store$MDE <- as.factor(store$MDE)

store50 <- store
```


```{r, eval = T}
# copy the exact same thing FOR VILLAGESIZE 30- ugly I know - quick fix
# we want to do the checks across clusternumbers for different values of ICC and MDE - split by the two avg clustersizes
rm(store)
store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 30, ICC_choice = 0.01, pr_incidence = p_diar, MDE = .2)) |> bind_rows()

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 30, ICC_choice = 0.02, pr_incidence = p_diar, MDE = .2)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 30, ICC_choice = 0, pr_incidence = p_diar, MDE = .2)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 30, ICC_choice = 0.01, pr_incidence = p_diar, MDE = .1)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 30, ICC_choice = 0.02, pr_incidence = p_diar, MDE = .1)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one

store <- lapply(clusternumbers, function(x) power_cpa.binary(x, clusize_avg = 30, ICC_choice = 0, pr_incidence = p_diar, MDE = .1)) |> bind_rows() |> bind_rows(store) # stitch onto the previos one


store$ICC <- as.factor(store$ICC)
store$MDE <- as.factor(store$MDE)

store30 <- store

```


```{r, eval = T, include = T, }
# find the entry that is closest to 80 and 90%
#library(kableExtra)
closepowerfinder <- function(df, target_value) {df[which.min(abs(df$power - target_value)), ]}
store <- bind_rows(store30, store50)
storesubs <- store |> group_by(clusize_avg, MDE, ICC) |> do(closepowerfinder(.,.90))
storesubs <- storesubs |> filter(MDE == .2)
storesubs$power <- round(storesubs$power, 1)
names(storesubs) <- c("avg_clustersize", "diarrhea incidence", "MDE", "ICC", "villages_needed", "power")
knitr::kable(storesubs, caption = "Number of villages needed for different scenarios (total, both arms - numbers extracted from the powercurves in the figures below).") #|> column_spec(6, border_right = T) |> kable_styling()
```



```{r plotpoweravgsize30, eval = T, include = T,  fig.width=7, fig.height=4, fig.align='center'}


#ggplot(store, aes(x = nclusters, y = power, col = ICC, linetype = MDE, shape = MDE)) + 
p <- ggplot(store30, aes(x = nclusters, y = power, 
                       #col = interaction(ICC, MDE, sep = ' - '),
                       col = MDE,
                       #shape = interaction(MDE, ICC, sep = ' - '),
                       shape = ICC,
                       #linetype = interaction(MDE, ICC, sep = ' - '),
                       linetype = MDE,
                       )) + 
  geom_point() + geom_line() + 
  ggtitle("Power for total number of villages, avg size: 30") +
  theme_bw() +
  guides(colour = guide_legend(override.aes = list(shape = NA))) +
  labs(colour="MDE", shape="ICC") + scale_color_DIL() +
  scale_x_discrete(name = "Number of villages", limits = seq(50, 900, by = 50)) + 
  scale_y_discrete(name = "power", limits = seq(0, 1, by = .1), expand = c(0.05,0.1)) # shrink default expansion (0.6 for discrete) 

p

```




```{r plotpoweravgsize50, eval = T, include = T,  fig.width=7, fig.height=4, fig.align='center'}


#ggplot(store, aes(x = nclusters, y = power, col = ICC, linetype = MDE, shape = MDE)) + 
p <- ggplot(store50, aes(x = nclusters, y = power, 
                       #col = interaction(ICC, MDE, sep = ' - '),
                       col = MDE,
                       #shape = interaction(MDE, ICC, sep = ' - '),
                       shape = ICC,
                       #linetype = interaction(MDE, ICC, sep = ' - '),
                       linetype = MDE,
                       )) + 
  geom_point() + geom_line() + 
  ggtitle("Power for total number of villages, avg size: 50") +
  theme_bw() +
  guides(colour = guide_legend(override.aes = list(shape = NA))) +
  labs(colour="MDE", shape="ICC") + scale_color_DIL() +
  scale_x_discrete(name = "Number of villages", limits = seq(50, 900, by = 50)) + 
  scale_y_discrete(name = "power", limits = seq(0, 1, by = .1), expand = c(0.05,0.05)) # shrink default expansion (0.6 for discrete) 

p

```


\newpage

# 2) Simulation: multiple rounds of data collection

The simulation code that is used here models the data generating process (DGP) as draws from a Bernoulli distribution with a cluster level random effect that induces ICC. The events (diarrhea incidence) within individuals across rounds are modeled with an **i.i.d. error to first give a benchmark scenario**. In the subsequent section we assume a correlated error term that induces an AR(1) process to approximately match the data in Pickering et. al. (2019). The simulations are carried out 1,000 times for each dot that is visualized.

To showcase that the code delivers meaningful power estimates, the plots at the end of this section showcase the scenario where the number of rounds in the simulations is 1. It can be seen that the resulting power curves are very similar to the results from above, verifying that they can approximate the results from the plug-in formula well. Note that the curve for MDEs of 10% is a bit wobbly due to the small effect size, a larger amount of iterations would straighten them out further. 

## 2.1) Simulations with 3 rounds, iid errors

As indicated in the introduction, there are substantial power gains from additional rounds - mostly because we add additional diarrhea incidences to the data. The following table summarizes the scenarios where power is approximately 80%, extracted from the values that you can see in the plot - as in the plug-in formula case. **To get a better picture for the power numbers it is ideal to check the interpolated values in the plots**. The plots trace out the full power curve (note that there are less dots as compared to the above because for every value we need a substantial amount of simulations, which is computationally very costly given the many different scenarios).

```{r, eval = T, include = T}
#df.sim.iid <- readRDS("powerruns_stored/sim_3rounds_allvalues_2ICC2MDE2vilsize_NoAR1_1kruns.RDS")
# only include the fingrained version - I checked and the two coincide for when we have same villagesize in both
df.sim.iid <- readRDS("powerruns_stored/sim_3rounds_allvalues_2ICC2MDE2vilsize_NoAR1_1kruns_finervillagejumps.RDS")

storesubsiid <- df.sim.iid |> group_by(clusize, MDE, ICC) |> do(closepowerfinder(.,.90))
#storesubs <- storesubs |> filter(MDE == .2)
storesubsiid$power <- round(storesubsiid$power, 2)
storesubsiid$diarrhea_pc <- .05
storesubsiid <- storesubsiid |> select(-cor12)
names(storesubsiid) <- c("villages_needed", "MDE", "avg_clustersize",  "power", "ICC", "diarrhea incidence")
storesubsiid <- storesubsiid[, c("avg_clustersize", "diarrhea incidence", "MDE", "ICC", "villages_needed", "power")]

storesubs20 <- storesubsiid |> filter(MDE == .2)
storesubs20 |># group_by(MDE) |> 
  knitr::kable(caption = "Effectsize 20%, 3 rounds. Number of villages needed for different scenarios (total, both arms - numbers extracted from the powercurves in the figures below).", digits = 2)
```

```{r, eval = T, include = T}

storesubs10 <- storesubsiid |> filter(MDE == .1)
storesubs10 |># group_by(MDE) |> 
  knitr::kable(caption = "Effectsize 10%, 3 rounds. Number of villages needed for different scenarios (total, both arms - numbers extracted from the powercurves in the figures below).", digits = 2)

```



```{r plotsimpowerIID, eval = T, include = T,  fig.width=7, fig.height=8, fig.align='center', fig.cap='Power with three rounds of data collection. Upper panel: 30 U5 children per village. Lower panel: 50 U5 children per village.'}
# load the data that was stored from the power_odisha_diarrhea_runs.R file for one round


p <- ggplot(df.sim.iid, aes(x = nclusters, y = power, 
                       #col = interaction(ICC, MDE, sep = ' - '),
                       col = MDE,
                       #shape = interaction(MDE, ICC, sep = ' - '),
                       shape = ICC,
                       #linetype = interaction(MDE, ICC, sep = ' - '),
                       linetype = MDE,
                       )) + 
  geom_point() + geom_line() + 
  #ggtitle("Power for total number of villages, avg size: 30") +
  theme_bw() +
  guides(colour = guide_legend(override.aes = list(shape = NA))) +
  labs(colour="MDE", shape="ICC") + scale_color_DIL() +
  scale_x_discrete(name = "Number of villages", limits = seq(50, 900, by = 50)) + 
  scale_y_discrete(name = "power", limits = seq(0, 1, by = .1), expand = c(0.025,0.05)) +
  facet_wrap( ~ clusize, nrow = 2, scales = 'free')# shrink default expansion (0.6 for discrete) 

p

```

\newpage 

## 2.2) Simulations with 3 rounds, AR(1) errors

Results are essentially the same as above for reasonable degrees of autocorrelation because the number of periods is so low.

```{r, eval = F, include = F}
df.sim.AR1 <- readRDS(file = "powerruns_stored/sim_3rounds_allvalues_2ICC2MDE2vilsize_1kruns.RDS")

storesubsiid <- df.sim.AR1 |> group_by(clusize, MDE, ICC) |> do(closepowerfinder(.,.90))
#storesubs <- storesubs |> filter(MDE == .2)
storesubsiid$power <- round(storesubsiid$power, 2)
storesubsiid$diarrhea_pc <- .05
names(storesubsiid) <- c("villages_needed", "MDE", "avg_clustersize",  "power", "ICC", "diarrhea incidence")
storesubsiid <- storesubsiid[, c("avg_clustersize", "diarrhea incidence", "MDE", "ICC", "villages_needed", "power")]

storesubs20 <- storesubsiid |> filter(MDE == .2)
storesubs20 |># group_by(MDE) |> 
  knitr::kable(caption = "Number of villages needed for different scenarios. Effectsize 20% (total, both arms - numbers extracted from the powercurves in the figures below)")
```

```{r, eval = F, include = F}

storesubs10 <- storesubsiid |> filter(MDE == .1)
storesubs10 |># group_by(MDE) |> 
  knitr::kable(caption = "Number of villages needed for different scenarios. Effectsize 10% (total, both arms - numbers extracted from the powercurves in the figures below)")

```



```{r plotsimpowerAR1, eval = F, include = F,  fig.width=7, fig.height=8, fig.align='center', fig.cap='Power with three rounds of data collection. Upper panel: 30 U5 children per village. Lower panel: 50 U5 children per village.'}
# load the data that was stored from the power_odisha_diarrhea_runs.R file for one round


p <- ggplot(df.sim.AR1, aes(x = nclusters, y = power, 
                       #col = interaction(ICC, MDE, sep = ' - '),
                       col = MDE,
                       #shape = interaction(MDE, ICC, sep = ' - '),
                       shape = ICC,
                       #linetype = interaction(MDE, ICC, sep = ' - '),
                       linetype = MDE,
                       )) + 
  geom_point() + geom_line() + 
  #ggtitle("Power for total number of villages, avg size: 30") +
  theme_bw() +
  guides(colour = guide_legend(override.aes = list(shape = NA))) +
  labs(colour="MDE", shape="ICC") + scale_color_DIL() +
  scale_x_discrete(name = "Number of villages", limits = seq(50, 900, by = 50)) + 
  scale_y_discrete(name = "power", limits = seq(0, 1, by = .1), expand = c(0.025,0.05)) +
  facet_wrap( ~ clusize, nrow = 2, scales = 'free')# shrink default expansion (0.6 for discrete) 

p

```



## 2.3) Showcase that simulations with 1 round match formulas

```{r plotsimpowerconfirm, eval = T, include = T,  fig.width=7, fig.height=8, fig.align='center', fig.cap='Showcase the working of the simulation code by setting the number of rounds to 1 and matching the results from the plug-in formulas above.'}
# load the data that was stored from the power_odisha_diarrhea_runs.R file for one round
df.sim.1 <- readRDS("powerruns_stored/sim_1round_allvalues_2comparewithformulaoutput.RDS")


p <- ggplot(df.sim.1, aes(x = nclusters, y = power, 
                       #col = interaction(ICC, MDE, sep = ' - '),
                       col = MDE,
                       #shape = interaction(MDE, ICC, sep = ' - '),
                       shape = ICC,
                       #linetype = interaction(MDE, ICC, sep = ' - '),
                       linetype = MDE,
                       )) + 
  geom_point() + geom_line() + 
  #ggtitle("Power for total number of villages, avg size: 30") +
  theme_bw() +
  guides(colour = guide_legend(override.aes = list(shape = NA))) +
  labs(colour="MDE", shape="ICC") + scale_color_DIL() +
  scale_x_discrete(name = "Number of villages", limits = seq(50, 900, by = 50)) + 
  scale_y_discrete(name = "power", limits = seq(0, 1, by = .1), expand = c(0.025,0.05)) +
  facet_wrap( ~ clusize, nrow = 2)# shrink default expansion (0.6 for discrete) 

p

```




```{r}
# then on July12th there was a response by MK

# Hi, 
# 
# Thanks so much for your email. Sone quick reactions
# 
# I think we need to pick up smaller than 25% reductions in diarrhea. 
# 
# I don't think we can afford three rounds of data collection within our current budget. Can we get cost estimates? These calculations suggest the ratio of cost of mortality to diarrhea power is high for ILC India relative to individually randomizable treatments.
# 
# what ICC is being used?
# 
# I think it's critical to take into account intra-cluster correlation. 
# 
#  Can you share all the parameters that are assumed? 
# 
# Does this involve any baseline data collection? 
# 
# IIt would be great if you could share the code that you're using as well. 
# 
# I'm a little confused because I thought there was supposed to be 150 villages rather than 100. 
# 
# Best Wishes,
# Michael

# ------------------------
 # Akankhsa then said in Person on July 13th at Booth during DIL teamweek that they only put 150 to have buffer (befoer it was 80 and they put 100 to have buffer). She also said that new village numbers will be based on outcome of power calculations


# ------------------------
# later the same day, Elisa wrote on the pickering slack
# Hi 
# @Alex Lehner
#  can you calculate how many villages we need if we want to do 1 data collection for U2 mortality with ICC NOT zero (we considered 0.01 in the past right?). What MK wants to know is the trade-off to do 1 data collection with 3 times the sample or 3 rounds of data collection with less sample. We are going to ask for additional funds to GiveWell so we would like to budget for both scenarios after we know the required sample size for a MDE < 25% (maybe 20%? or maybe 15%, but with 95% power, NO less). Then we can put together the budget and think about the trade-offs 0 Thanks a lot!



# -----------
# Not included in response to Elisa: Just as a quick back of the envelope to anticipate: for just having one round, given 50 U5children per village, a 95% powered MDE of 20% would require 550 villages




```

\newpage

# 3) Descriptives from Pickering et. al. (2019, The Lancet)

Pickering et. al. (2019): 100 shared water points (clusters) in two low-income urban communities in Bangladesh were randomly assigned (1:1) to have their drinking water automatically chlorinated at the point of collection by a solid tablet chlorine doser (intervention group) or to be treated by a visually identical doser that supplied vitamin C (active control group). The trial followed an open cohort design; all children younger than 5 years residing in households accessing enrolled water points were measured every 2–3 months during a 14-month follow-up period (children could migrate into or out of the cluster). The primary outcome was caregiver-reported child diarrhoea (more than 2 loose or watery stools in a 24-h period [WHO criteria]) with a 1-week recall, including all available childhood observations in the analyses. Children in the treatment group had less WHO-defined diarrhoea than did children in the control group (control 216 [10.0%] of 2154; treatment 156 [7.5%] of 2073; prevalence ratio 0.77, 95% CI 0.65–0.91).

They collected 7 rounds in total and found an effect of roughly 25% (diarrhea incidence reduction). The study was block-randomized by matching pairs, i.e. there are 50 randomization blocks with one cluster each assigned to treatment and control.


```{r, eval=TRUE, include=FALSE}
# find real world data from Amy's Bangladesh study in the Lancet
amy_lancet <- readstata13::read.dta13("../data/amypickering_lancet_BGD/chlorine_diarrhea_public.dta")
amy_lancet <- amy_lancet[!is.na(amy_lancet$uniqueid_entered), ]
# in paper we have 3142 and 3063 child-observations
(3142 + 3063) # number matches
table(amy_lancet$tr) # is the treatment variable

# POWER WORDING
# We	powered	the	study	to	detect	a	25%	reduction	in	the	WHO	case	definition	of	diarrhea;	our	sample	size	calculations	assumed,	based	on	prior	work,	that	diarrhea	prevalence	would	be	10%	among	children	<5	years	of	age	in	the	study	area.	We	conducted	the	power	calculations	using	a	cluster-level	means	approach	(comparing	the	mean	diarrhea	prevalence	by	cluster-time-point	between	groups)	because	we	did	not	have	a	good	estimate	for	the	intracluster	correlation	coefficient	for	diarrhea	by	water	point.	This	approach	treats	repeated	measures	at	one	point	in	time	the	same	as	repeated	measures	over	time.	Using	this	approach,	we	calculated	that	we	would	have	96%	power	with	the	study	design	(50	clusters	per	arm,	10	children	per	cluster)

table(amy_lancet$child_diarrhea)
amy_lancet$child_diarrhea1 <- ifelse(amy_lancet$child_diarrhea == "Yes", 1, 0) # make 01
table(amy_lancet$child_diarrhea1) # check
amy_lancet |> group_by(tr) |> summarise(meandia = mean(child_diarrhea1, na.rm = T))

# counts
amy_lancet |> count(round, tr, child_diarrhea1)

# ICC
fixest::feols(child_diarrhea1 ~ 0 | Block, data = amy_lancet)
fixest::feols(child_diarrhea1 ~ 0 | pumpid, data = amy_lancet) # 0.021 as compared to 0.025 in paper


logitamy <- glm(child_diarrhea1 ~ tr + round + Block, data = amy_lancet, family = "binomial")
summary(logitamy)


olsamy <- fixest::feols(child_diarrhea1 ~ tr | Block + round, data = amy_lancet)
summary(olsamy)
meanctrl <- mean(amy_lancet$child_diarrhea1[amy_lancet$tr != "trchlorine"]) 
(meanctrl + olsamy$coefficients) / meanctrl


```

```{r, eval = T}
# wanna see ICC + block effect
# wanna do the calc with how many unique 1's in the diarrhea case
# run the regression with indiv FE and error
olsamy <- fixest::feols(child_diarrhea1 ~ tr | round + Block, data = amy_lancet)
summary(olsamy)
summary(olsamy, vcov = ~ Block)
summary(olsamy, vcov = ~ pumpid)
summary(olsamy, vcov = ~ childidfull)
summary(olsamy, vcov = ~ Block + childidfull)

# get the means per round
amy_lancet |> group_by(round) |> summarise(meandiarrhea = mean(child_diarrhea1))

# run regression per round and see if the weighted average fits:
roundreg <- amy_lancet |> group_by(round) |> summarise(ols = fixest::feols(child_diarrhea1 ~ tr | Block, data = cur_data())$coefficients,
                                           tstats = summary(fixest::feols(child_diarrhea1 ~ tr | Block, data = cur_data()))$coeftable[1,3],
                                           nobs = fixest::feols(child_diarrhea1 ~ tr | Block, data = cur_data())$nobs)

roundreg$ols |> weighted.mean(w = roundreg$nobs)

# check the round FE - i.e. the means in the control group in every round
test <- fixest::feols(child_diarrhea1 ~ tr | round, data = amy_lancet)
fixest::fixef(test) # |> plot()
```


```{r meansperround, eval = T, include = T }
knitr::kable(amy_lancet |> group_by(round,tr) |> summarise(meandiarrhea = mean(child_diarrhea1)) |> pivot_wider(id_cols = round, names_from = tr, values_from = meandiarrhea), caption = "Diarrhea incidence for every round of collection, broken down by treatment and control group.", digits = 3)

```



```{r, eval = T}
# TABLES PRINTED BELOW - NEXT TO AUTOCORRELATION

# checking diarrhea frequency

amy_lancet <- amy_lancet |> group_by(childidfull) |> mutate(diarrhea_count = sum(child_diarrhea1))

table(amy_lancet$diarrhea_count)
table(amy_lancet$diarrhea_count[amy_lancet$tr == "chlorine"])
table(amy_lancet$diarrhea_count[amy_lancet$tr != "chlorine"])


# UNIQUE CHILDREN
amy_lancet$diarrhea_ever <- ifelse(amy_lancet$diarrhea_count > 0, 1, 0) # assign a 1 if a child ever had diarrhea at some point
amy_lancet_unique <- amy_lancet[!duplicated(amy_lancet$childidfull), ]
table(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr == "chlorine"])
table(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr != "chlorine"])
mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr == "chlorine"])
mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr != "chlorine"])
# effect on unique
mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr == "chlorine"]) / mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr != "chlorine"])

logitever <- glm(diarrhea_ever ~ tr, data = amy_lancet_unique, family = "binomial")
summary(logitever)
exp(logitever$coefficients[2])
# effsize
olsever<- fixest::feols(diarrhea_ever ~ tr, data = amy_lancet_unique)
summary(olsever)
meanctrl <- mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr != "chlorine"])
(meanctrl + olsever$coefficients[2]) / meanctrl

# effect is lower

# now we do a final thing and see how many new, independent cases get added with each round
amy_lancet$diarrhea_first <- 0

amy_lancet <- amy_lancet %>%
  #select(childidfull, round, child_diarrhea1, diarrhea_count) |> 
  group_by(childidfull) %>%
  arrange(round) |> # need to arrange by round here, otherwise the first assignment would not work - it rests on the thing being orderd
  mutate(first_1 = child_diarrhea1 == 1 & !duplicated(child_diarrhea1 == 1))  %>%
  arrange(childidfull)


amy_lancet$diarrhea_first <- ifelse(amy_lancet$first_1 == TRUE, 1, 0)


# get the percentage point add per round
roundsummary <- amy_lancet |> group_by(round) |> summarise(diarrheanew = mean(diarrhea_first)) 
roundsummary$diarrheanew |> sum()
amy_lancet |> group_by(round) |> summarise(diarrheanew = mean(diarrhea_first)) 

mean(amy_lancet$child_diarrhea1)
mean(amy_lancet$diarrhea_first)
mean(amy_lancet_unique$diarrhea_ever)
# THIS DOES NOT WORK BECAUSE NOT EVERY CHILD HAS SAME NUMBER OF ROUNDS

```



#### Intra-cluster correlation (ICC)

```{r iccest, eval = T, include = F}
# ICC
fixest::feols(child_diarrhea1 ~ 0 | Block, data = amy_lancet)
fixest::feols(child_diarrhea1 ~ 0 | pumpid, data = amy_lancet) |> fixest::r2()# 0.021 as compared to 0.025 in paper
#ICC::ICCest(pumpid, child_diarrhea1, data = amy_lancet)$ICC
#ICCbin::iccbin(pumpid, child_diarrhea1, data = amy_lancet, method = "aov")

# period ICCs a bit more severe
amy_lancet |> group_by(round) |> summarise(ICC = ICC::ICCest(pumpid, child_diarrhea1, data = cur_data())$ICC)


# ICC for the block randomization
amy_lancet$residual4ICC <- lm(child_diarrhea1 ~ Block, data = amy_lancet)$resid

#ICC::ICCest(pumpid, residual4ICC, data = amy_lancet)$ICC

# CHANGE OF ICC
# SEE BELOW FOR THE ICC ON THE COUNT
#amy_lancet |> group_by(childidfull) |> mutate(indiv_resid = residual4ICC)


#amy_lancet |> group_by(round) |> summarise(temp = lm(child_diarrhea1 ~ Block, data = cur_data())$resid)


```

We calculate the raw ICC to be `r round(ICC::ICCest(pumpid, child_diarrhea1, data = amy_lancet)$ICC, 4)` and `r round(ICC::ICCest(pumpid, residual4ICC, data = amy_lancet)$ICC, 4)` after taking into account the blocking structure of the experiment. The sample size is not very large and we thus have reasons to believe that these estimates are not very precise. From earlier data work on child mortality with substantially larger sample sizes we obtained estimates of around 0.01. We therefore want to use 0.01 and 0.02 as benchmark values in our power calculations. 


#### Autocorrelation

Using the residual of the main specification of interest - a regression of diarrhea on a treatment indicator with block and round fixed effects - from Pickering et. al. (2019), we can estimate an autocorrelation parameter. Specifically, we are regressing the error from that regression on its lagged values, forcing the intercept to be 0:

$$e_{it} = \rho \ e_{i,t-1} + \epsilon_{it}.$$

```{r autocorrest, eval = T, include = F}

# AUTOCORRELATION
# check how the lag works
data.frame(id = c(1,1,1,2,2,2), val = rep(1:3, 2)) |> group_by(id) |> 
  mutate(lagged = lag(val, n = 1, default = NA, order_by = id))

olsamy <- fixest::feols(child_diarrhea1 ~ tr | round + Block, data = amy_lancet)
# estimate 
amy_lancet$err <- olsamy$residuals
# remove intercept with -1
autocorr <- lm(err ~ -1 + lag(err), data = amy_lancet)
autocorr$coefficients[[1]]

# CHECK LAGGED DEPENDENT VARIABLE
# sort by id and round first (is sorted by default? no but the order_By does the job):
amy_lancet <- amy_lancet %>%                           
  group_by(childidfull) %>%
  dplyr::mutate(laggedval = lag(child_diarrhea1, n = 1, default = NA, order_by = round))
#View(amy_lancet |> select(round, child_diarrhea1, laggedval, diarrhea_count))

amy_lancet |> group_by(round) |> summarise(corr = cor(child_diarrhea1, laggedval, use = "complete.obs"))

#lm(child_diarrhea1 ~ laggedval + as.factor(childidfull), data = amy_lancet) |> summary()
ARreg <- fixest::feols(child_diarrhea1 ~ laggedval | childidfull, data = amy_lancet)
summary(ARreg)
# lmtest::dwtest(ARreg)
# car::durbinWatsonTest(ARreg)
autocorrelation <- sapply(split(amy_lancet$child_diarrhea1, amy_lancet$childidfull), function(x) acf(x, plot = FALSE)$acf[2])
mean_autocorrelation <- mean(autocorrelation, na.rm = T)





# 100 villages with roughly 50
# broken down also by trt now

```


Alternatively, we can also check the raw correlation between the diarrhea incidence in every round with its lagged value (omitting round 1 by force because we to not observe $t=0$.):


```{r lagcorrperround, eval = T, include = T}
#amy_lancet |> group_by(round, tr) |> summarise(diarrheanew = mean(diarrhea_first)) 

#amy_lancet |> group_by(round, tr) |> summarise(corr = cor(child_diarrhea1, laggedval, use = "complete.obs"))
knitr::kable(amy_lancet |> group_by(round) |> summarise(corr = cor(child_diarrhea1, laggedval, use = "complete.obs")), caption = "Raw correlation of diarrhea incidence and its lagged value, broken down per round", digits = 3)

```



The following table shows the counts of the total number of diarrhea cases over the seven rounds per child. The maximum number of cases per child was 5, while most children that had diarrhea only had it in one out of seven rounds.

```{r, eval = T, include = T}
amy_lancet <- amy_lancet |> group_by(childidfull) |> mutate(diarrhea_count = sum(child_diarrhea1))
amy_lancet_unique <- amy_lancet[!duplicated(amy_lancet$childidfull), ] # do not doublecount the entries
# DIARRHEA COUNTS
table(amy_lancet_unique$diarrhea_count)
#table(amy_lancet$diarrhea_count[amy_lancet$tr == "chlorine"])
#table(amy_lancet$diarrhea_count[amy_lancet$tr != "chlorine"])
```

In terms of percent, these numbers look as follows:

```{r, eval = T, include = T}
(table(amy_lancet_unique$diarrhea_count) / nrow(amy_lancet_unique)) |> round(3)
```


```{r, eval = T}

# UNIQUE CHILDREN
amy_lancet$diarrhea_ever <- ifelse(amy_lancet$diarrhea_count > 0, 1, 0) # assign a 1 if a child ever had diarrhea at some point
amy_lancet_unique <- amy_lancet[!duplicated(amy_lancet$childidfull), ]
table(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr == "chlorine"]) 
table(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr != "chlorine"])
mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr == "chlorine"])
mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr != "chlorine"])
```

The percentage of children in the control group that ever had diarrhea is `r mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr != "chlorine"]) |> round(3) * 100` and in the control group `r mean(amy_lancet_unique$diarrhea_ever[amy_lancet_unique$tr == "chlorine"]) |> round(3) * 100` percent of children had diarrhea recorded at least once.

When we divide the table on counts by the number of children that ever had diarrhea (instead of the total number of children), the percentages look as follows:


```{r, eval = T, include = T}
(table(amy_lancet_unique$diarrhea_count)[-1] / sum(amy_lancet_unique$diarrhea_ever)) |> round(3)
```


```{r}
amy_lancet_unique$diarrhea_substr <- amy_lancet_unique$diarrhea_count
(amy_lancet_unique$diarrhea_substr[amy_lancet_unique$diarrhea_substr > 0] - 1) |> sum() # cases that are beyond a single diarrhea case
((amy_lancet_unique$diarrhea_substr[amy_lancet_unique$diarrhea_substr > 0] - 1) |> sum() ) / sum(amy_lancet_unique$diarrhea_count)
```


```{r}
# ICC ON COUNTS
ICC::ICCest(pumpid, diarrhea_count, data = amy_lancet_unique)$ICC

amy_lancet_unique$residual4ICC <- lm(diarrhea_count ~ Block, data = amy_lancet_unique)$resid

ICC::ICCest(pumpid, residual4ICC, data = amy_lancet_unique)$ICC

# 0.02886731 and 0.02168379 for the counts, raw and blocked
```



### Checking counts per cluster


```{r, eval = T, include = T, fig.width = 4, fig.height = 3, fig.cap = "Diarrhea counts per cluster (pump), summed over all 7 rounds - approximately Poisson."}

amy_counts <- amy_lancet |> group_by(pumpid) |> summarise(n_people = n(),
                                                          diarrh_n = sum(child_diarrhea1),
                                                          tr = tr[1])

# diarrhea counts per pump
pois_lamb <- mean(amy_counts$diarrh_n)
pois_lamb1 <- sd(amy_counts$diarrh_n) # not too bad, looks like pois (obviously since it is counts)
library(ggh4x); library(fitdistrplus) # had troubles to fit the dpoits without these
#ggplot(data = amy_counts, aes(diarrh_n)) + geom_histogram(aes(y = stat(density))) + geom_density()
#ggplot(data = amy_counts, aes(diarrh_n)) + geom_histogram(aes(y = stat(density))) +  geom_density(aes(dpois(1:25, lambda = pois_lamb)))
#ggplot(data = amy_counts, aes(diarrh_n)) + geom_histogram(aes(y = stat(density))) + geom_density() + stat_theodensity(distri = "pois", col = "red")


ggplot(data = amy_counts) + geom_histogram(aes(diarrh_n)) + facet_grid(~ tr) + theme_bw()


#plot(dpois(1:25, lambda = pois_lamb))
```

\newpage

